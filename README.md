3학년 2학기 텍스트데이터분석 교과이수중 수행한 프로젝트
# Web Scraping & NLP Analysis

## 1. 프로젝트 개요

이 프로젝트는 네이버 뉴스에서 특정 주제를 중심으로 웹 스크래핑을 수행하고,  
수집한 뉴스 데이터를 텍스트 분석을 통해 의미 있는 정보를 추출하는 프로젝트입니다.

- 웹 스크래핑을 통해 **15,000개 이상의 뉴스 기사**를 확보
- 텍스트 데이터의 **전처리 및 NLP 분석 수행**
- 최소 **2가지 이상의 NLP 기법 적용** (Word Cloud, Topic Modeling 등)

---

## 2. 프로젝트 목표

이 프로젝트는 **텍스트 데이터 수집, 전처리, 분석**을 수행하는 것을 목표로 합니다.

1. **데이터 수집**  
   - 관심 있는 주제 5개 이상에 대한 뉴스 데이터를 수집  
   - 네이버 뉴스 API를 이용하여 기사 데이터 확보  
   - 웹 스크래핑을 통해 **최소 15,000개 이상의 문서** 확보  

2. **데이터 전처리**  
   - 불필요한 HTML 태그 및 특수 문자 제거  
   - 중복 뉴스 필터링 및 중복 제거  
   - 불용어(Stopwords) 제거  
   - Tokenization (형태소 분석, 토큰화)  
   - Normalization (소문자 변환, 철자 교정 등)  
   - Stemming & Lemmatization (어간/표제어 추출)  

3. **텍스트 분석 수행**  
   아래 작업들 중 **최소 2가지 이상**을 수행합니다.  
   - **Word Cloud**: 단어 빈도수를 시각적으로 표현  
   - **Topic Modeling (LDA)**: 문서의 숨겨진 주제를 분석하여 확률적으로 추정  
   - **Text Classification**: 뉴스 기사 분류 모델 적용  
   - **Similar Document Retrieval**: 유사 문서 검색 시스템 구현  


---
1. 네이버뉴스에서 특정쿼리문을 사용하여 웹스크래핑

2. 가져온 문서들의 stopwords들을 preprocessing

3. wordcloud로 단어의 빈도수를 확인하여 직관적으로 문서들의 내용을 파악

4. LDA로 포함된 문서들이 어떤 토픽들로 구성되어있는지 확률적으로 추정
