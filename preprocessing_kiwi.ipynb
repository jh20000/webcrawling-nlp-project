{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kiwipiepy import Kiwi\n",
    "import re\n",
    "import copy\n",
    "\n",
    "\n",
    "# 필요한 객체 및 변수 정의\n",
    "kiwi = Kiwi(typos='basic') #typos = basic -> 토큰화(형태소 분석)시에 기본적인 오탈자 교정해줌\n",
    "\n",
    "# 분석 대상 키워드\n",
    "query = '교회' \n",
    "df = pd.read_csv(f'./Raw_Content/기독교_본문/{query}_content.csv') \n",
    "# 본문(content) 스크래핑 결과가 Nan인 값을 제거\n",
    "df = df.dropna(subset=['body'],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 종교별 키워드를 불용어 처리에 사용 - 종교적 맥락을 너무 저해한다고 판단 주석처리 \n",
    "# Christianity_stop = ['기독교','교회','하나님','개신교','목사','예수']\n",
    "# Catholicism_stop = ['천주교','수녀님','성당','하느님','신부님','교황','추기경']\n",
    "# Buddhism_stop = ['불교','부처님','절','스님','승려','보살']\n",
    "news_stop = ['해당 기사', '제공', '이메일', '카카오톡', '제보', '노컷뉴스', '무단', '전재','배포']\n",
    "add_stop = ['상황', '곳', '뒤', '후', '앞', '이번','종교',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#종교별 데이터수 균형을 맞추기 위함함\n",
    "#df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy.utils import Stopwords # kiwi에서 제공하는 Stopword list\n",
    "stopwords = Stopwords()\n",
    "\n",
    "# 기본 불용어 + 사용자 불용어 통합\n",
    "default_stopwords = stopwords.stopwords\n",
    "stopwords = set(default_stopwords)  # 기본 불용어를 set으로 변환\n",
    "custom_stopwords = set(news_stop + add_stop) #+ Christianity_stop + Catholicism_stop + Buddhism_stop )\n",
    "\n",
    "stopwords.update((word, 'NNG') for word in custom_stopwords)  # 사용자 불용어 추가 (보통명사)\n",
    "stopwords.update((word, 'NNP') for word in custom_stopwords)  # 사용자 불용어 추가 (고유명사)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]')  # 한글만 필터링 \n",
    "\n",
    "def preprocess_korean(text, analyzer=kiwi, stopwords=stopwords, return_list=False):\n",
    "    my_text = str(text).replace('\\n', ' ')  # 개행 제거\n",
    "    my_text = analyzer.space(my_text)  # 띄어쓰기 교정\n",
    "\n",
    "    \n",
    "    sents = analyzer.split_into_sents(my_text) #문장 토큰화\n",
    "    all_result = []\n",
    "\n",
    "    for sent in sents:\n",
    "        token_result = analyzer.tokenize(sent.text)#단어 토큰화\n",
    "        tmp = []  # \n",
    "        for token in token_result:\n",
    "            # 명사(NNG, NNP, 동사, 형용사)만 추출 & 불용어 제거 -> 명사 대명사만 필터링\n",
    "            if (token.form, token.tag) not in stopwords and token.tag in ['NNG', 'NNP']:\n",
    "                tmp.append(token.form)\n",
    "\n",
    "        token_result = ' '.join(tmp)\n",
    "        token_result = p.sub(' ', token_result)  # 한글 이외 문자 제거\n",
    "        all_result.append(token_result)\n",
    "\n",
    "    return all_result if return_list else ' '.join(all_result)  # 리스트로 반환 옵션 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pre_body'] = df['body'].apply(lambda x: preprocess_korean(x)) # 전처리기 적용\n",
    "df.to_csv(f'../modeling/Preprocessed_Content/preprocessed_{query}.csv', index=False)  # 전처리된 결과를 담은 csv 저장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kiwi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
